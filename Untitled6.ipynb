{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzr8twbwmGsImevmlpIwWf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZMAins3a-hy","executionInfo":{"status":"ok","timestamp":1687158187034,"user_tz":-330,"elapsed":14560,"user":{"displayName":"Vikas Kumar Tiwari","userId":"15032654506679697144"}},"outputId":"67574af0-8a64-4210-8489-ad7cf3ff871f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sklearn\n","  Using cached sklearn-0.0.post5.tar.gz (3.7 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"]}],"source":["!pip install sklearn\n","!pip install pandas\n","!pip install numpy\n","!pip install keras"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from matplotlib import pyplot as plt"],"metadata":{"id":"JOTFJNqDd8x-","executionInfo":{"status":"ok","timestamp":1687158395054,"user_tz":-330,"elapsed":19,"user":{"displayName":"Vikas Kumar Tiwari","userId":"15032654506679697144"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#load the dataset\n","data=pd.read_csv('/content/dataset.csv')\n","data.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"kQZiLJRAe2fC","executionInfo":{"status":"ok","timestamp":1687158701137,"user_tz":-330,"elapsed":420,"user":{"displayName":"Vikas Kumar Tiwari","userId":"15032654506679697144"}},"outputId":"6b44e57c-02f7-447e-c920-219bd5750537"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n","0            6      148             72  ...                     0.627   50        1\n","1            1       85             66  ...                     0.351   31        0\n","2            8      183             64  ...                     0.672   32        1\n","3            1       89             66  ...                     0.167   21        0\n","4            0      137             40  ...                     2.288   33        1\n","\n","[5 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-4b3fdc9b-07b9-4a97-a1e9-c12a340a76c0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b3fdc9b-07b9-4a97-a1e9-c12a340a76c0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4b3fdc9b-07b9-4a97-a1e9-c12a340a76c0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4b3fdc9b-07b9-4a97-a1e9-c12a340a76c0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#the objective is to predict based on diagnostic measurements whether a patient has diabetes."],"metadata":{"id":"wGD0w1Zyf7hC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#preparing data for modelling\n","predictors=data.iloc[0:,0:8]\n","response=data.iloc[:,8]"],"metadata":{"id":"sYjBlhnN0tg0","executionInfo":{"status":"ok","timestamp":1687164305804,"user_tz":-330,"elapsed":482,"user":{"displayName":"Vikas Kumar Tiwari","userId":"15032654506679697144"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["#create training and testing variables\n","x_train,x_test,y_train,y_test=train_test_split(predictors,response,test_size=0.2)\n","x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2,random_state=1)"],"metadata":{"id":"1YhjI5vP1LKq","executionInfo":{"status":"ok","timestamp":1687164532434,"user_tz":-330,"elapsed":393,"user":{"displayName":"Vikas Kumar Tiwari","userId":"15032654506679697144"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["#training the neural network model\n","#There are two ways to build keras models: sequential and functional.\n","#The sequential method allows you to create models layer-by-layer"],"metadata":{"id":"sh5DYISz1_w6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define the keras model- layer by layer\n","kerasmodel=Sequential()    #initializing model Dense for fully connected layer\n","kerasmodel.add(Dense(12,input_dim=8,activation='relu'))   #first hidden layer\n","kerasmodel.add(Dense(8,activation='relu'))                 #second hidden layer\n","kerasmodel.add(Dense(1,activation='sigmoid'))    #since output is binary so sigmoid,,,,,output layer\n","#note: weight and bias initialization are done by keras default."],"metadata":{"id":"W49fKGQ52sh-","executionInfo":{"status":"ok","timestamp":1687165211825,"user_tz":-330,"elapsed":422,"user":{"displayName":"Vikas Kumar Tiwari","userId":"15032654506679697144"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["#compile the model\n","kerasmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"],"metadata":{"id":"-30FslQ55vAk","executionInfo":{"status":"ok","timestamp":1687165817142,"user_tz":-330,"elapsed":718,"user":{"displayName":"Vikas Kumar Tiwari","userId":"15032654506679697144"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["#fitting the model\n","history=kerasmodel.fit(x_train,y_train,epochs=350,batch_size=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzvzZM8K653-","executionInfo":{"status":"ok","timestamp":1687166394601,"user_tz":-330,"elapsed":41288,"user":{"displayName":"Vikas Kumar Tiwari","userId":"15032654506679697144"}},"outputId":"de8e583a-f25e-4169-8daf-8cced1c6c96a"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7699\n","Epoch 2/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7800\n","Epoch 3/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7760\n","Epoch 4/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7475\n","Epoch 5/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7678\n","Epoch 6/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7271\n","Epoch 7/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7495\n","Epoch 8/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7841\n","Epoch 9/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7678\n","Epoch 10/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7760\n","Epoch 11/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7699\n","Epoch 12/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7617\n","Epoch 13/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7576\n","Epoch 14/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7617\n","Epoch 15/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7576\n","Epoch 16/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7556\n","Epoch 17/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7800\n","Epoch 18/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7556\n","Epoch 19/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7597\n","Epoch 20/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7556\n","Epoch 21/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7597\n","Epoch 22/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7515\n","Epoch 23/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7841\n","Epoch 24/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7902\n","Epoch 25/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7576\n","Epoch 26/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7780\n","Epoch 27/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7373\n","Epoch 28/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7862\n","Epoch 29/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7841\n","Epoch 30/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7923\n","Epoch 31/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7637\n","Epoch 32/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7719\n","Epoch 33/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7780\n","Epoch 34/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7862\n","Epoch 35/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7536\n","Epoch 36/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7800\n","Epoch 37/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7719\n","Epoch 38/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7678\n","Epoch 39/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7862\n","Epoch 40/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7862\n","Epoch 41/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7862\n","Epoch 42/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7719\n","Epoch 43/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7923\n","Epoch 44/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7495\n","Epoch 45/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7821\n","Epoch 46/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7658\n","Epoch 47/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7902\n","Epoch 48/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7536\n","Epoch 49/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7719\n","Epoch 50/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7699\n","Epoch 51/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7821\n","Epoch 52/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7658\n","Epoch 53/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7658\n","Epoch 54/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7923\n","Epoch 55/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7902\n","Epoch 56/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7780\n","Epoch 57/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7862\n","Epoch 58/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7841\n","Epoch 59/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7800\n","Epoch 60/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7821\n","Epoch 61/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7821\n","Epoch 62/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7637\n","Epoch 63/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7800\n","Epoch 64/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.8024\n","Epoch 65/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7739\n","Epoch 66/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7760\n","Epoch 67/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7963\n","Epoch 68/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7862\n","Epoch 69/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.8004\n","Epoch 70/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7658\n","Epoch 71/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7637\n","Epoch 72/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7658\n","Epoch 73/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7617\n","Epoch 74/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7780\n","Epoch 75/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7780\n","Epoch 76/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7963\n","Epoch 77/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7739\n","Epoch 78/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7862\n","Epoch 79/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7943\n","Epoch 80/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7780\n","Epoch 81/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7760\n","Epoch 82/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7800\n","Epoch 83/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7821\n","Epoch 84/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7862\n","Epoch 85/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7963\n","Epoch 86/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7963\n","Epoch 87/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7902\n","Epoch 88/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7800\n","Epoch 89/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7556\n","Epoch 90/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7719\n","Epoch 91/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7902\n","Epoch 92/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7678\n","Epoch 93/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7902\n","Epoch 94/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7841\n","Epoch 95/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7678\n","Epoch 96/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7556\n","Epoch 97/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7719\n","Epoch 98/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7984\n","Epoch 99/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7841\n","Epoch 100/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7658\n","Epoch 101/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7699\n","Epoch 102/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7780\n","Epoch 103/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7658\n","Epoch 104/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7719\n","Epoch 105/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7882\n","Epoch 106/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7800\n","Epoch 107/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7821\n","Epoch 108/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7902\n","Epoch 109/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7658\n","Epoch 110/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7923\n","Epoch 111/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7637\n","Epoch 112/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7699\n","Epoch 113/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8024\n","Epoch 114/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7862\n","Epoch 115/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7760\n","Epoch 116/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7739\n","Epoch 117/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7760\n","Epoch 118/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7943\n","Epoch 119/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8004\n","Epoch 120/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7963\n","Epoch 121/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7699\n","Epoch 122/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7719\n","Epoch 123/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7841\n","Epoch 124/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7780\n","Epoch 125/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7943\n","Epoch 126/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7800\n","Epoch 127/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7882\n","Epoch 128/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7678\n","Epoch 129/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7739\n","Epoch 130/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7780\n","Epoch 131/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7821\n","Epoch 132/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7821\n","Epoch 133/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7800\n","Epoch 134/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7760\n","Epoch 135/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7576\n","Epoch 136/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7637\n","Epoch 137/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7800\n","Epoch 138/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7699\n","Epoch 139/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7821\n","Epoch 140/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8004\n","Epoch 141/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7963\n","Epoch 142/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7821\n","Epoch 143/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7800\n","Epoch 144/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7800\n","Epoch 145/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7862\n","Epoch 146/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7719\n","Epoch 147/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7943\n","Epoch 148/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7800\n","Epoch 149/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7841\n","Epoch 150/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7821\n","Epoch 151/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7678\n","Epoch 152/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7780\n","Epoch 153/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7800\n","Epoch 154/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7821\n","Epoch 155/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.8065\n","Epoch 156/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7699\n","Epoch 157/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7821\n","Epoch 158/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7821\n","Epoch 159/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7841\n","Epoch 160/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7637\n","Epoch 161/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7963\n","Epoch 162/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7739\n","Epoch 163/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7434\n","Epoch 164/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7760\n","Epoch 165/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7658\n","Epoch 166/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7678\n","Epoch 167/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7780\n","Epoch 168/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7862\n","Epoch 169/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7658\n","Epoch 170/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7923\n","Epoch 171/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7780\n","Epoch 172/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7862\n","Epoch 173/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7984\n","Epoch 174/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7862\n","Epoch 175/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7800\n","Epoch 176/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7984\n","Epoch 177/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7923\n","Epoch 178/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7699\n","Epoch 179/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7882\n","Epoch 180/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7637\n","Epoch 181/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7800\n","Epoch 182/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7576\n","Epoch 183/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7841\n","Epoch 184/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7760\n","Epoch 185/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7923\n","Epoch 186/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7760\n","Epoch 187/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8086\n","Epoch 188/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8004\n","Epoch 189/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.8004\n","Epoch 190/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7780\n","Epoch 191/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7699\n","Epoch 192/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7699\n","Epoch 193/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8004\n","Epoch 194/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7882\n","Epoch 195/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7760\n","Epoch 196/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7800\n","Epoch 197/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7800\n","Epoch 198/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8045\n","Epoch 199/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882\n","Epoch 200/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7780\n","Epoch 201/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7862\n","Epoch 202/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7739\n","Epoch 203/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7943\n","Epoch 204/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7902\n","Epoch 205/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7862\n","Epoch 206/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7739\n","Epoch 207/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7882\n","Epoch 208/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7576\n","Epoch 209/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7658\n","Epoch 210/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7678\n","Epoch 211/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7821\n","Epoch 212/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7251\n","Epoch 213/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7862\n","Epoch 214/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7821\n","Epoch 215/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7902\n","Epoch 216/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7862\n","Epoch 217/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7800\n","Epoch 218/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7821\n","Epoch 219/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7699\n","Epoch 220/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7800\n","Epoch 221/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8065\n","Epoch 222/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7923\n","Epoch 223/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8024\n","Epoch 224/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7841\n","Epoch 225/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8004\n","Epoch 226/350\n","50/50 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8004\n","Epoch 227/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7923\n","Epoch 228/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7943\n","Epoch 229/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7902\n","Epoch 230/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8045\n","Epoch 231/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7902\n","Epoch 232/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7821\n","Epoch 233/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7536\n","Epoch 234/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7943\n","Epoch 235/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8024\n","Epoch 236/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7841\n","Epoch 237/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7760\n","Epoch 238/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7800\n","Epoch 239/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7821\n","Epoch 240/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7780\n","Epoch 241/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7841\n","Epoch 242/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8004\n","Epoch 243/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7984\n","Epoch 244/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7841\n","Epoch 245/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7963\n","Epoch 246/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8024\n","Epoch 247/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7923\n","Epoch 248/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8004\n","Epoch 249/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8045\n","Epoch 250/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7943\n","Epoch 251/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7821\n","Epoch 252/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7800\n","Epoch 253/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7943\n","Epoch 254/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7923\n","Epoch 255/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8106\n","Epoch 256/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7821\n","Epoch 257/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7902\n","Epoch 258/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7984\n","Epoch 259/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7821\n","Epoch 260/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8004\n","Epoch 261/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7841\n","Epoch 262/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7963\n","Epoch 263/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7902\n","Epoch 264/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7821\n","Epoch 265/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8004\n","Epoch 266/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8004\n","Epoch 267/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7984\n","Epoch 268/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7923\n","Epoch 269/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7841\n","Epoch 270/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7862\n","Epoch 271/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7923\n","Epoch 272/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7963\n","Epoch 273/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7760\n","Epoch 274/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7862\n","Epoch 275/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7882\n","Epoch 276/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7617\n","Epoch 277/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7862\n","Epoch 278/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7943\n","Epoch 279/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7902\n","Epoch 280/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7882\n","Epoch 281/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7536\n","Epoch 282/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7658\n","Epoch 283/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7902\n","Epoch 284/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8086\n","Epoch 285/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7515\n","Epoch 286/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7780\n","Epoch 287/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7821\n","Epoch 288/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7923\n","Epoch 289/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8106\n","Epoch 290/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7800\n","Epoch 291/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7760\n","Epoch 292/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7882\n","Epoch 293/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7923\n","Epoch 294/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7841\n","Epoch 295/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.8086\n","Epoch 296/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7882\n","Epoch 297/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7943\n","Epoch 298/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7923\n","Epoch 299/350\n","50/50 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7800\n","Epoch 300/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7800\n","Epoch 301/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7882\n","Epoch 302/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7841\n","Epoch 303/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8045\n","Epoch 304/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7780\n","Epoch 305/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7821\n","Epoch 306/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7760\n","Epoch 307/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8024\n","Epoch 308/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8045\n","Epoch 309/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8187\n","Epoch 310/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8004\n","Epoch 311/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8045\n","Epoch 312/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7902\n","Epoch 313/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7699\n","Epoch 314/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7963\n","Epoch 315/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7963\n","Epoch 316/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7821\n","Epoch 317/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7902\n","Epoch 318/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7862\n","Epoch 319/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7617\n","Epoch 320/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7862\n","Epoch 321/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7821\n","Epoch 322/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7841\n","Epoch 323/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7739\n","Epoch 324/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7841\n","Epoch 325/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7923\n","Epoch 326/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7576\n","Epoch 327/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7923\n","Epoch 328/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7515\n","Epoch 329/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7800\n","Epoch 330/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7902\n","Epoch 331/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8004\n","Epoch 332/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7963\n","Epoch 333/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7943\n","Epoch 334/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7963\n","Epoch 335/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8045\n","Epoch 336/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7780\n","Epoch 337/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7943\n","Epoch 338/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7821\n","Epoch 339/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7760\n","Epoch 340/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8004\n","Epoch 341/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7862\n","Epoch 342/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8004\n","Epoch 343/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7963\n","Epoch 344/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7862\n","Epoch 345/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8147\n","Epoch 346/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7882\n","Epoch 347/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7739\n","Epoch 348/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7963\n","Epoch 349/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7943\n","Epoch 350/350\n","50/50 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7882\n"]}]},{"cell_type":"code","source":["#train accuracy\n","accuracy=kerasmodel.evaluate(x_train,y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkGuCub38d5N","executionInfo":{"status":"ok","timestamp":1687166418197,"user_tz":-330,"elapsed":391,"user":{"displayName":"Vikas Kumar Tiwari","userId":"15032654506679697144"}},"outputId":"40170f80-21f2-4e33-fcc3-992f1eaaffc3"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["16/16 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.7923\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HpwXYXSwCQOP"},"execution_count":null,"outputs":[]}]}